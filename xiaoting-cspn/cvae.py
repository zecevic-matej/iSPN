# -*- coding: utf-8 -*-
"""cvae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/generative/cvae.ipynb

##### Copyright 2018 The TensorFlow Authors.
"""

from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf

import sys
import time
from datetime import datetime
import numpy as np
import matplotlib.pyplot as plt
import argparse
import configurations as cf

import model as modelpy
import model_vae
import RAT_SPN
import region_graph

# Unused:
# from IPython import display
# import PIL
# import imageio
# import os
# import glob


class CVAE(tf.keras.Model):
    # TODO not working probably

    def __init__(self, latent_dim, x_ph):
        super(CVAE, self).__init__()
        self.x_ph = x_ph
        self.latent_dim = latent_dim
        self.inference_net = self.create_encoder()
        self.generative_net = self.define_gen_model()

        self.loss = self.get_loss()
        self.optimizer = self.get_optimizer(self.loss)

    def define_gen_model(self):
        net = tf.keras.Sequential(
            [
                tf.keras.layers.InputLayer(input_shape=(self.latent_dim,)),
                tf.keras.layers.Dense(units=7 * 7 * 32, activation=tf.nn.relu),
                tf.keras.layers.Reshape(target_shape=(7, 7, 32)),
                tf.keras.layers.Conv2DTranspose(
                    filters=64,
                    kernel_size=3,
                    strides=(2, 2),
                    padding="SAME",
                    activation='relu'),
                tf.keras.layers.Conv2DTranspose(
                    filters=32,
                    kernel_size=3,
                    strides=(2, 2),
                    padding="SAME",
                    activation='relu'),
                # No activation
                tf.keras.layers.Conv2DTranspose(
                    filters=1, kernel_size=3, strides=(1, 1), padding="SAME"),
            ]
        )
        return net

    def create_encoder(self):
        if args.dataset == "mnist":
            return model_vae.build_nn_mnist(self.x_ph, self.latent_dim)
        else:
            return model_vae.build_nn_celeb_baseline(self.x_ph, self.latent_dim)

    def sample(self, eps=None):
        if eps is None:
            eps = tf.random_normal(shape=(100, self.latent_dim))
        return self.decode(eps, apply_sigmoid=True)

    def encode(self, x):
        mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)
        return mean, logvar

    def get_loss(self):
        mean, logvar = self.encode(self.x_ph)
        z = self.reparameterize(mean, logvar)
        x_logit = self.decode(z)

        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit,
                                                            labels=self.x_ph)
        logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])
        logpz = log_normal_pdf(z, 0., 0.)
        logqz_x = log_normal_pdf(z, mean, logvar)
        return -tf.reduce_mean(logpx_z + logpz - logqz_x)

    def get_optimizer(self, loss):
        optimizer = tf.train.AdamOptimizer(1e-4)
        train_op = optimizer.minimize(loss)
        return train_op

    def reparameterize(self, mean, logvar):
        eps = tf.random_normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    def decode(self, z, apply_sigmoid=False):
        logits = self.generative_net(z)
        if apply_sigmoid:
            probs = tf.sigmoid(logits)
            return probs

        return logits


class ECSPN(tf.keras.Model):
    """
    Encoded conditional SPN
    """
    def __init__(self, latent_dim, x_ph, configuration):
        super(ECSPN, self).__init__()
        self.x_ph = x_ph
        self.x_shape = self.x_ph.get_shape().as_list()
        self.latent_dim = latent_dim
        self.configuration = configuration

        self.inference_net = self.create_encoder()
        mean, logvar = self.encode()
        z = self.reparameterize(mean, logvar)

        self.cspn = self.create_cspn(z)

        self.loss = self.get_loss(z, mean, logvar)
        self.optimizer = self.get_optimizer()

    def create_encoder(self):
        if args.dataset == "mnist":
            return model_vae.build_nn_mnist(self.x_ph, self.latent_dim)
        else:
            return model_vae.build_nn_celeb_baseline(self.x_ph, self.latent_dim)

    def create_cspn(self, z):
        num_copies = 8
        num_splits = 2
        num_recursions = 2     # need 18000 params for 3, > 2560 for 2
        num_leaf_param = int(num_copies * num_splits * num_recursions)

        # TODO check sum parameters, they are unchanged
        if args.dataset == "mnist":
            sum_weights, leaf_weights = model_vae.build_nn_mnist_latentspace(
                z, self.x_shape, 2600, num_leaf_param, self.configuration)
        else:
            sum_weights, leaf_weights = model_vae.build_nn_celeb_latentspace(
                z, self.x_shape, 2600, num_leaf_param, self.configuration)
        param_provider = RAT_SPN.ScopeBasedParamProvider(sum_weights, leaf_weights)

        with tf.variable_scope("spn"):
            rg = region_graph.RegionGraph(range(int(np.prod(self.x_shape[1:]))))
            for _ in range(0, num_copies):
                rg.random_split(num_splits, num_recursions)

            spn_args = RAT_SPN.SpnArgs()
            spn_args.normalized_sums = True
            spn_args.param_provider = param_provider
            spn_args.num_sums = 8
            spn_args.num_gauss = int(num_leaf_param / num_copies)

            spn_args.dist = 'Bernoulli'
            spn = RAT_SPN.RatSpn(1, region_graph=rg, name="spn", args=spn_args)
            print("created SPN")
        return spn

    def get_loss(self, z, mean, logvar):
        x_ph_reshaped = tf.reshape(self.x_ph, (self.x_shape[0], -1))
        logpx_z = self.cspn.forward(x_ph_reshaped)
        # TODO reshape fix?
        logpx_z = tf.reshape(logpx_z, shape=[self.x_shape[0]])

        logpz = log_normal_pdf(z, 0., 0.)
        logqz_x = log_normal_pdf(z, mean, logvar)

        out = -tf.reduce_mean(logpx_z + logpz - logqz_x)
        return out

    def get_optimizer(self):
        optimizer = tf.train.AdamOptimizer(1e-4)
        train_op = optimizer.minimize(self.loss)
        return train_op

    def encode(self):
        # TODO change for MNIST NN
        mean, logvar = tf.split(self.inference_net, num_or_size_splits=2, axis=1)
        return mean, logvar

    def reparameterize(self, mean, logvar):
        eps = tf.random_normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    def sample(self, eps=None):
        raise NotImplementedError


class VMDN(tf.keras.Model):
    """
    Mixture Density Network
    """
    def __init__(self, latent_dim, x_ph, k):
        super(VMDN, self).__init__()
        self.x_ph = x_ph
        self.x_shape = self.x_ph.get_shape().as_list()
        self.latent_dim = latent_dim
        self.k = k

        self.inference_net = self.create_encoder()
        self.generative_net = self.create_generator()
        self.alpha_net = self.create_alpha_net()
        mean, logvar = self.encode()
        z = self.reparameterize(mean, logvar)

        self.mdn = self.create_mdn(z)

        self.loss = self.get_loss(z, mean, logvar)
        self.optimizer = self.get_optimizer()

    def create_encoder(self):
        if args.dataset == "mnist":
            return model_vae.build_nn_mnist(self.latent_dim)
        else:
            return model_vae.build_nn_celeb_baseline(self.latent_dim)

    def create_generator(self):
        net = tf.keras.Sequential(
            [
                tf.keras.layers.InputLayer(input_shape=(self.latent_dim,)),
                tf.keras.layers.Dense(units=7 * 7 * 32, activation=tf.nn.relu),
                tf.keras.layers.Reshape(target_shape=(7, 7, 32)),
                tf.keras.layers.Conv2DTranspose(
                    filters=64,
                    kernel_size=3,
                    strides=(2, 2),
                    padding="SAME",
                    activation='relu'),
                tf.keras.layers.Conv2DTranspose(
                    filters=32,
                    kernel_size=3,
                    strides=(2, 2),
                    padding="SAME",
                    activation='relu'),
                # No activation
                tf.keras.layers.Conv2DTranspose(
                    filters=self.k, kernel_size=3, strides=(1, 1), padding="SAME"),
                tf.keras.layers.Reshape((784, self.k)),
            ]
        )
        return net

    def create_alpha_net(self):
        return tf.keras.Sequential(
            [
                tf.keras.layers.InputLayer(input_shape=(self.latent_dim,)),
                tf.keras.layers.Dense(units=100, activation=tf.nn.relu),
                tf.keras.layers.Dense(units=100, activation=tf.nn.relu),
                tf.keras.layers.Dense(units=50, activation=tf.nn.relu),
                tf.keras.layers.Dense(units=self.k, activation=tf.nn.softmax),
            ]
        )

    def create_mdn(self, z):
        # TODO that is actually unused
        n_labels = np.prod(self.x_shape[1:])

        mdn_weights = self.generative_net(z)
        alpha_weights = self.alpha_net(z)

        print("mdn weights: ", mdn_weights)
        with tf.variable_scope("mdn"):
            mdn = modelpy.MixtureDensityNetwork\
                (mdn_weights, self.k, n_labels, alpha_weights=alpha_weights)
            print("created MDN")
        return mdn

    def get_optimizer(self):
        optimizer = tf.train.AdamOptimizer(1e-4)
        train_op = optimizer.minimize(self.loss)
        return train_op

    def reparameterize(self, mean, logvar):
        eps = tf.random_normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    def sample(self, eps=None):
        raise NotImplementedError

    def encode(self):
        mean, logvar = tf.split(self.inference_net(self.x_ph), num_or_size_splits=2, axis=1)
        return mean, logvar

    def get_loss(self, z, mean, logvar):
        x_ph_reshaped = tf.reshape(self.x_ph, (self.x_shape[0], -1))
        logpx_z = self.mdn.forward(x_ph_reshaped)

        logpz = log_normal_pdf(z, 0., 0.)
        logqz_x = log_normal_pdf(z, mean, logvar)
        return -tf.reduce_mean(logpx_z + logpz - logqz_x)


class ECVAETrainer:
    """
    Trainer for each of the VAE classes
    """

    def __init__(self, run_config, model, x_ph, tensorboard_stuff):
        self.run_config = run_config
        self.epochs = args.epochs
        self.batch_size = run_config["batch_size"]
        self.debug = args.debug
        self.x_ph = x_ph
        self.train_writer = tensorboard_stuff[0]
        self.test_writer = tensorboard_stuff[1]
        self.summary_op = tensorboard_stuff[2]
        # TODO:
        # self.train_writer =

        self.model = model

    def train_and_val(self, train_images, test_images, sess):
        train_batches_in_epoch = train_images.shape[0] // self.batch_size

        print("Start Training")
        for epoch in range(1, self.epochs + 1):
            start_time = time.time()
            total_loss = 0

            for i in range(train_batches_in_epoch):
                x_batch = train_images[i * self.batch_size: (i + 1) * self.batch_size]
                feed_dict = {self.x_ph: x_batch}

                # TODO:
                # show_nice_progress_bar(count, 600)

                cur_loss, summary, _ = sess.run([self.model.loss, self.summary_op,
                                                self.model.optimizer], feed_dict=feed_dict)
                total_loss += cur_loss

                if i % 6 == 0:
                    cur_step = i + epoch * train_batches_in_epoch
                    self.train_writer.add_summary(summary, cur_step)

                    # On test data:
                    j = i // 6
                    test_x = test_images[j * self.batch_size: (j + 1) * self.batch_size]
                    if test_x.shape[0] < self.batch_size:
                        test_x = test_images[0:self.batch_size]
                        print(j, i)
                    feed_dict = {self.x_ph: test_x}
                    summary = sess.run(self.summary_op, feed_dict=feed_dict)
                    self.test_writer.add_summary(summary, cur_step)

                if self.debug:
                    break

            elbo = -(total_loss / train_batches_in_epoch)
            end_time = time.time()

            # TODO:
            # clean_printed_line()

            print('\nEpoch: {}\nTrain set ELBO: {}, time for training {}'
                  .format(epoch, elbo, end_time - start_time))

            if epoch % 1 == 0:
                self.test_batch(test_images, sess)

        print("Finished Training")

    def test_batch(self, test_images, sess):
        test_batches_in_epoch = test_images.shape[0] // self.batch_size

        start_time = time.time()
        total_loss = 0
        for j in range(test_batches_in_epoch):
            feed_dict = {self.x_ph: test_images[j * self.batch_size: (j + 1) * self.batch_size]}

            cur_loss = sess.run(self.model.loss, feed_dict=feed_dict)
            total_loss += cur_loss
            if self.debug:
                break

        elbo = -(total_loss / test_batches_in_epoch)
        end_time = time.time()
        print("Test set ELBO: {}, time for testing {}"
              .format(elbo, end_time - start_time))

        # TODO:
        # generate_and_save_images(model, epoch, random_vector_for_generation)


"""
Util functions
"""


def log_normal_pdf(sample, mean, logvar, raxis=1):
    log2pi = tf.log(2. * np.pi)
    return tf.reduce_sum(
        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),
        axis=raxis)


def generate_and_save_images(model, epoch, test_input):
    print("Generating Image")
    predictions = model.sample(test_input)
    fig = plt.figure(figsize=(4, 4))

    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i+1)
        plt.imshow(predictions[i, :, :, 0], cmap='gray')
        plt.axis('off')

    # tight_layout minimizes the overlap between 2 sub-plots
    plt.savefig('./gen_images/image_at_epoch_{:04d}.png'.format(epoch))
    plt.show()


def load_binarized_mnist():
    """
    Load the MNIST dataset
    Each MNIST image is originally a vector of 784 integers, each of which is
    between 0-255 and represents the intensity of a pixel.
    We model each pixel with a Bernoulli distribution in our model, and we statically
    binarize the dataset.
    """

    (train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()

    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')

    # Normalizing the images to the range of [0., 1.]
    train_images /= 255.
    test_images /= 255.

    # Binarization
    train_images[train_images >= .5] = 1.
    train_images[train_images < .5] = 0.
    test_images[test_images >= .5] = 1.
    test_images[test_images < .5] = 0.

    return train_images, test_images


def load_celeb(size=128):
    """
    Load Celelb dataset
    :return: train and test images, labels not needed
    """
    if args.debug:
        # Load Fake Celeb Dataset:
        # Create Vectors with 1s or 0s
        train_x = np.ones((2000, 128, 128, 3))
        test_x = np.ones((500, 128, 128, 3))
    else:
        path = './work/data/celeba/'
        train_x = np.load(path + 'celeb{}-train.npy'.format(size))
        test_x = np.load(path + 'celeb{}-test.npy'.format(size))
        # train_y = np.load(path + 'celeb-train-labels.npy')
        # test_y = np.load(path + 'celeb-test-labels.npy')
    return train_x, test_x


def show_nice_progress_bar(current, maximal):
    maximal -= 1
    progress = "\rProgress: <"
    for _ in range(current // 10):
        progress += "#"
        if current % 10 != 0:
            progress += str(current % 10)
        else:
            progress += "-"
    for _ in range(maximal // 10 - current // 10):
        progress += "-"
    leading_zero_i = str(current).zfill(len(str(maximal)))
    progress += f"> {leading_zero_i}/{maximal}"
    sys.stdout.write(progress)
    sys.stdout.flush()


def clean_printed_line():
    sys.stdout.write("\x1b[2K\r")
    sys.stdout.flush()


def setup_tensorboard(loss, model_config):
    loss_summary = tf.summary.scalar("loss", loss)
    summary_op = tf.summary.merge([loss_summary])
    cur_time = str(datetime.now())[:19].replace(' ', '--')
    log_dir = "./logs/" + args.architecture + "/" \
              + args.name + model_config["name"] + args.dataset + cur_time
    train_writer = tf.summary.FileWriter(log_dir + '/train',
                                         graph=tf.get_default_graph())
    test_writer = tf.summary.FileWriter(log_dir + '/test',
                                        graph=tf.get_default_graph())

    return train_writer, test_writer, summary_op


def get_model(x_ph, model_config, run_config):
    if args.architecture == "spn":
        model = ECSPN(model_config["latent_dim"], x_ph, model_config)
        # print(model.inference_net.summary())
    elif args.architecture == "vae":
        model = CVAE(model_config["latent_dim"], x_ph)
        # print(model.inference_net.summary())
        print(model.generative_net.summary())
    elif args.architecture == "mdn":
        model = VMDN(model_config["latent_dim"], x_ph, args.mdn_k)
        # print(model.inference_net.summary())
        print(model.generative_net.summary())
    else:
        print(f"Model {args.architecture} not specified")
        model = None
        exit()

    return model


def run_single_configuration(model_config, run_config, train_images, test_images):

    # --------- DEFINE MODEL & TF --------
    input_shape = train_images.shape[1:]
    input_shape = np.insert(input_shape, 0, run_config["batch_size"])
    print("Input Shape x:", input_shape)
    x_ph = tf.placeholder(tf.float32, input_shape)
    model = get_model(x_ph, model_config, run_config)
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    # -------- TENSORBOARD ----------
    train_writer, test_writer, summary_op = setup_tensorboard(model.loss, model_config)
    tensorboard_stuff = [train_writer, test_writer, summary_op]

    # -------- INIT TRAINER ---------
    trainer = ECVAETrainer(run_config, model, x_ph, tensorboard_stuff)

    # -------- RUN TRAINING --------
    trainer.train_and_val(train_images, test_images, sess)

    # ------- RESET -------
    sess.close()
    tf.reset_default_graph()
    tf.summary.FileWriterCache.clear()


def load_data():
    if args.dataset == "mnist":
        train_images, test_images = load_binarized_mnist()
    else:
        train_images, test_images = load_celeb()
        # TODO remove, its for testing
        # train_images, test_images = load_binarized_mnist()
    return train_images, test_images


def main():

    run_config = cf.standard_run
    model_configs = cf.good_configuration

    if args.debug:
        run_config["num_examples_to_generate"] = 1

    train_images, test_images = load_data()
    for config in model_configs:
        run_single_configuration(config, run_config, train_images, test_images)

    # TODO:
    # random_vector_for_generation = tf.random_normal(shape=[num_examples_to_generate, latent_dim])
    # generate_and_save_images(model, 0, random_vector_for_generation)


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description="Conditional SPN over latent space z")
    parser.add_argument("-d", "--debug", action="store_true",
                        help="Runs training on mininmal settings for debugging")
    parser.add_argument("-e", "--epochs", default=100, type=int,
                        help="Set number of epochs")
    parser.add_argument("-a", "--architecture", default="spn", choices=["spn", "vae", "mdn"])
    parser.add_argument("-k", "--mdn_k", default=1, type=int,
                        help="If architecture == mdn set number of distr")
    parser.add_argument("-n", "--name", default="",
                        help="Name will be added to tensorboard log")
    parser.add_argument("--dataset", default="celeb", choices=["mnist", "celeb"],
                        help="Chose dataset to train on")

    args = parser.parse_args()

    if args.debug:
        args.epochs = 2
    print(f"\n-------Settings\n{args}\n--------\n")

    if args.debug:
        print("--------\n\nACTIVATE DEBUG MODE\n\n---------")

    main()
# TODO: define encoder and decoder beforehand and parse it to the networks
